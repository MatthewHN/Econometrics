{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo final Econometría\n",
    "## Estimador de salarios en puestos Tech de EEUU\n",
    "### Hecho por:\n",
    "- Matthew Samuel Horne Negro\n",
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Descripción de los datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hemos escogido una Base de Datos de Kagle sobre los salarios que perciben los empleados en puestos de trabajo de EEUU. Pensamos que puede resultar interesante analizar estos datos incluso para beneficio personal al haber integrantes del grupo que planteen la posibilidad de trabajar allí. Los datos están específicamente seleccionados de empresas en el sector Tech aunque como veremos hay puestos de Marketing y Recursos Humanos, pero estos son todos de empresas tecnológicas.**\n",
    "\n",
    "**La Base de Datos recoge con una muestra de más de 6500 empleados, sobre los que se proporciona la siguiente información:\n",
    "- Edad\n",
    "- Sexo,\n",
    "- Nivel de educación\n",
    "- Puesto de trabajo\n",
    "- Sños de experiencia en el puesto\n",
    "- Salario**\n",
    "\n",
    "**En este modelo trataremos de estimar el salario de un empleado conociendo el resto de variables**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeros modelos econométricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import statsmodels.stats.outliers_influence as oi\n",
    "import statsmodels.graphics.api as smg\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.stats.diagnostic as diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por comodidad nos gusta tener todos los imports juntos y no tener que estar repitiéndolos o ejecutando celdas específicas para no compilar todo el cuaderno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Salary_Data.csv')\n",
    "\n",
    "X = data.values[:, [0, 4]].astype(int)  # Age, Years of Experience\n",
    "Y = data.values[:, 5].astype(int)  # Salary\n",
    "\n",
    "results = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared (R-cuadrado):**\n",
    "\n",
    "R-squared es una medida de la bondad de ajuste del modelo de regresión. En este caso, el valor es 0.665, lo que significa que aproximadamente el 66.5% de la variabilidad en la variable dependiente (y) puede ser explicada por las variables independientes (x1 y x2) incluidas en el modelo. Un R-cuadrado más alto indica un mejor ajuste del modelo a los datos. Este se alcanzará conforme vayamos haciendo más complejo el modelo e introduzcamos más variables clave como Job Title o Education.\n",
    "\n",
    "**Adj. R-squared (R-cuadrado ajustado):**\n",
    "\n",
    "El R-cuadrado ajustado es similar al R-cuadrado, pero tiene en cuenta el número de variables independientes en el modelo. En este caso, el valor es también 0.665, lo que sugiere que el ajuste del modelo es consistente con el número de variables independientes incluidas.\n",
    "\n",
    "**F-statistic (Estadístico F):**\n",
    "\n",
    "El estadístico F se utiliza para evaluar la significación conjunta de todas las variables independientes en el modelo. Un valor grande del estadístico F (en este caso, 6539) con un p-valor pequeño (0.00) sugiere que al menos una de las variables independientes es significativa en la explicación de la variabilidad en la variable dependiente.\n",
    "\n",
    "**Coeficientes:**\n",
    "\n",
    "Bajo la sección \"coef\", se observan los coeficientes estimados para las variables en el modelo. En este caso, hay tres coeficientes: uno para la constante (intercepto), otro para x1 y otro para x2. Estos coeficientes indican cuánto cambia la variable dependiente (y) por unidad de cambio en las variables independientes (x1 y x2).\n",
    "Por ejemplo, el coeficiente para x2 es 9044.7257, lo que significa que, manteniendo todas las demás variables constantes, ceteris paribus, un aumento de una unidad en x2 se asocia con un aumento de aproximadamente 9044.7257 unidades en la variable dependiente (y), es decir, que en este caso por cada 1 año de experiencia más (Years of experience = x2) aumenta 9044.7257$ el salario (Salary = y)\n",
    "\n",
    "**Estadísticas adicionales:**\n",
    "\n",
    "Se proporcionan varias estadísticas adicionales, como el estadístico Omnibus, Durbin-Watson, Jarque-Bera, Skew, Kurtosis, entre otros. Estas estadísticas pueden ayudar a evaluar suposiciones sobre el modelo y la normalidad de los errores residuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:</strong> Al usar una base de datos con variables que son de tipo string para este primer modelo solo usaremos\n",
    "    variables numéricas y que han tenido que ser forzosamente convertidas a int porque si no, genera un error de tipos.\n",
    "    <br><br>\n",
    "    Más adelante habrá que convertir las variables categóricas en dummies para el correcto funcionamiento\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (Modelo de prueba no relacionado con los datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "X = np.random.normal(0, 10, n)\n",
    "Y = X + np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte = results.params[0]\n",
    "beta1 = results.params[1]\n",
    "\n",
    "plt.plot([-20, 20], [cte + beta1 * (-20), cte + beta1 * 20], color='r')\n",
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de los bloques realiza una simulación de datos y ajusta un modelo de regresión lineal a dichos datos.\n",
    "\n",
    "1. **Generación de Datos:** Se crean dos conjuntos de datos, X e Y, donde X son valores tomados de una distribución normal con una media de 0 y desviación estándar de 10, e Y es una función lineal de X más un término de error aleatorio normalmente distribuido. Esto simula una relación lineal entre X e Y con algo de ruido.\n",
    "\n",
    "2. **Visualización de Datos:** Se genera un gráfico de dispersión utilizando matplotlib para visualizar la relación entre X e Y. Cada punto representa una observación del conjunto de datos simulado.\n",
    "\n",
    "3. **Ajuste de Modelo de Regresión:** Se ajusta un modelo de regresión lineal ordinaria de mínimos cuadrados utilizando statsmodels con Y como variable dependiente y X como independiente. Se añade una constante al modelo para incluir un término de intercepto. Se imprime un resumen del modelo que proporciona detalles estadísticos del ajuste.\n",
    "\n",
    "4. **Visualización del Modelo de Regresión:** Se extraen el intercepto y la pendiente (coeficientes) del modelo ajustado y se utiliza para dibujar la línea de regresión sobre el gráfico de dispersión existente. La línea roja representa la relación estimada entre X e Y según el modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimación e Inferencia en Modelos de Regresión Lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Salary_Data.csv')\n",
    "\n",
    "# Muestra estadísticas descriptivas de las variables numéricas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Count (Conteo):** Muestra el número total de entradas (no nulas) para cada variable.\n",
    "    - En este caso, hay 6582 entradas para cada una de las variables: Age (Edad), Years of Experience (Años de Experiencia) y Salary (Salario).\n",
    "\n",
    "2. **Mean (Media):** Es el promedio de los valores para cada variable.\n",
    "    - La edad promedio es aproximadamente 33.57 años.\n",
    "    - Los años de experiencia promedio son aproximadamente 8.07 años.\n",
    "    - El salario promedio es de aproximadamente 115,768.67 unidades monetarias ($).\n",
    "\n",
    "3. **Std (Desviación Estándar):** Mide la cantidad de variación o dispersión de un conjunto de valores.\n",
    "    - La desviación estándar de la edad es aproximadamente 7.6 años, lo que indica la variabilidad de la edad en el conjunto de datos.\n",
    "    - La desviación estándar de los años de experiencia es de aproximadamente 6.04 años.\n",
    "    - La desviación estándar del salario es de aproximadamente 52,677.91, indicando la variabilidad en los salarios.\n",
    "\n",
    "4. **Min (Mínimo):** Es el valor más bajo en cada columna.\n",
    "    - La edad mínima es de 21 años.\n",
    "    - El mínimo de años de experiencia es 0 (personas sin experiencia previa).\n",
    "    - El salario mínimo es de 25,000.\n",
    "\n",
    "5. **25% (Percentil 25):** Este es el valor por debajo del cual se encuentra el 25% de los datos.\n",
    "    - 25% de los empleados tienen 28 años o menos.\n",
    "    - 25% tienen 3 años o menos de experiencia.\n",
    "    - 25% ganan 70,000 o menos.\n",
    "\n",
    "6. **50% (Mediana o Percentil 50):** Es el valor medio, donde la mitad de los datos está por debajo de este valor y la otra mitad por encima.\n",
    "    - La mediana de la edad es de 32 años.\n",
    "    - La mediana de los años de experiencia es de 7 años.\n",
    "    - La mediana del salario es de 115,000.\n",
    "\n",
    "7. **75% (Percentil 75):** El valor por debajo del cual se encuentra el 75% de los datos.\n",
    "    - 75% de los empleados tienen 38 años o menos.\n",
    "    - 75% tienen 12 años o menos de experiencia.\n",
    "    - 75% ganan 160,000 o menos.\n",
    "\n",
    "8. **Max (Máximo):** Es el valor más alto en cada columna.\n",
    "    - La edad máxima es de 62 años.\n",
    "    - El máximo de años de experiencia es de 34 años.\n",
    "    - El salario máximo es de 250,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], dtype=int)\n",
    "\n",
    "display(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:</strong> He estado horas atascado creando las dummies, al crear los dummies por defecto los tipos se establecen a TRUE o FALSE, sin embargo nosotros solo trabajamos con números así que, después de horas averigué que solo había que castearlo a tipo int (dtype=int).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['Salary']\n",
    "\n",
    "# Filtrar las columnas que comienzan con 'Education Level_*', 'Job Title_*' y 'Gender_*'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*', 'Job Title_*' y 'Gender_*' + 'Years of Experience' y 'Age'\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticos Descriptivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = np.mean(y)\n",
    "Q1 = np.quantile(y, 0.25)\n",
    "Q3 = np.quantile(y, 0.75)\n",
    "DesviacionTipica = np.std(y)\n",
    "Mediana = np.median(y)\n",
    "histograma = plt.hist(y, bins='auto', rwidth=0.85, density=True)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(\"Histograma de y (salary) ($)\")\n",
    "plt.show()\n",
    "print(\"Q1: \", Q1, \"($) Mediana:\", Mediana, \"($) Q3: \", Q3, \"($) DT: \", DesviacionTipica, \"($) Media:\", np.mean(y),\n",
    "      \"($)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Media: 115,768.67\n",
    "2. Primer Cuartil (Q1): 70,000.00\n",
    "3. Tercer Cuartil (Q3): 160,000.00\n",
    "4. Desviación Estándar: 52,673.91\n",
    "5. Mediana: 115,000.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.asarray(education_columns)\n",
    "mco1 = sm.OLS(y, X).fit()\n",
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:</strong> Como vemos ya se nos está avisando de que puede haber problemas con la multicolinealidad, intentaremos solucionarlo más adelante cuando llegue el momento quizás con una depuración manual de los datos o utilizando técnicas como el factor de inflación de la varianza (VIF) para identificar y posiblemente eliminar variables independientes que estén altamente correlacionadas.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretación de los resultados\n",
    "\n",
    "#### Medidas de Bondad de Ajuste:\n",
    "\n",
    "- **R-squared (R-cuadrado):**\n",
    "    El valor es 0.839, lo que indica que aproximadamente el 83.9% de la variabilidad en el salario se puede explicar con el modelo. Es una medida bastante alta de bondad de ajuste considerando que estamos tratando de estimar salarios.\n",
    "\n",
    "- **Adjusted R-squared (R-cuadrado ajustado):**\n",
    "    Con un valor de 0.837, después de ajustar por el número de predictores, sigue siendo muy alto, lo que indica que el modelo se ajusta bien a los datos.\n",
    "\n",
    "- **F-statistic (Estadístico F):**\n",
    "    Con un valor de 328.4 y un Prob (F-statistic) cercano a 0, sugiere que el modelo es estadísticamente significativo en su conjunto, es decir, hay evidencia de que al menos una de las variables independientes está relacionada con el salario.\n",
    "\n",
    "#### Diagnóstico de Residuos:\n",
    "- **Durbin-Watson:**\n",
    "    El valor es 0.216, que está muy por debajo de 2, sugiriendo la presencia de autocorrelación positiva entre los residuos, lo que podría ser un problema, ya que los residuos de un modelo bien ajustado deben ser independientes entre sí.\n",
    "\n",
    "- **Jarque-Bera (JB) y Prob(JB):**\n",
    "    -El valor del estadístico JB es 178.435 y el valor p es extremadamente pequeño, indicando que los residuos no siguen una distribución normal, lo cual es una violación de uno de los supuestos de la regresión OLS.\n",
    "\n",
    "- **Skew (Asimetría):**\n",
    "    El valor de -0.062 indica que la distribución de los residuos es ligeramente asimétrica, pero no es una preocupación mayor dado que está cerca de cero.\n",
    "\n",
    "- **Kurtosis:**\n",
    "    Un valor de 3.797 sugiere que la distribución de los residuos tiene colas más pesadas que una distribución normal, lo cual podría ser una señal de outliers o de un pico más pronunciado.\n",
    "\n",
    "- **Cond. No. (Número de Condición):**\n",
    "    El valor es extremadamente alto (4.75e+16), lo que indica la presencia de multicolinealidad entre las variables predictoras. Esto significa que algunas de las variables independientes están altamente correlacionadas entre sí, lo que puede inflar los errores estándar de los coeficientes y hacer que las estimaciones sean inestables.interpret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2 = mco1.params\n",
    "plt.plot(datos['Years of Experience'], y, 'o', color='r')\n",
    "xmin = np.min(datos['Years of Experience'])\n",
    "xmax = np.max(datos['Years of Experience'])\n",
    "\n",
    "plt.plot([xmin, xmax], [beta2.iloc[0] + beta2.iloc[1] * xmin, beta2.iloc[0] + beta2.iloc[1] * xmax])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.graphics.plot_regress_exog(mco1, 'Years of Experience'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = mco1.resid\n",
    "print(e)\n",
    "print(np.mean(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor obtenido sugiere que, en promedio, el modelo subestima ligeramente el valor real. Sin embargo, en el contexto de los modelos de regresión, un promedio de residuos de aproximadamente -5.7624e-10 podría considerarse insignificante, especialmente si la escala de la variable de respuesta (salario en este caso) es grande, como en decenas o cientos de miles. Este resultado es una señal de que el modelo está bien calibrado en términos de no tener un sesgo sistemático hacia sobreestimaciones o subestimaciones en las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suma de Cuadrados Totales (SCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.centered_tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa la variabilidad total en la variable dependiente. Es igual a la suma de las diferencias al cuadrado entre cada valor observado y la media de todos los valores observados. Un valor de 18262027724544.66 indica el total de variabilidad en tu variable dependiente que el modelo busca explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suma de Cuadrados Explicada (SCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.ess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa la variabilidad en la variable dependiente que es explicada por el modelo. Es igual a la suma de las diferencias al cuadrado entre los valores predichos por el modelo y la media de la variable dependiente. Un valor de 15326748750986.516 sugiere que esta es la cantidad de variabilidad que el modelo ha logrado explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suma de Cuadrados de los residuos (SCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa la variabilidad en la variable dependiente que no es explicada por el modelo. Es igual a la suma de los cuadrados de los residuos (errores) del modelo. Un valor de 2935278973558.1436 indica la cantidad de variabilidad que el modelo no ha podido explicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $R^2$ y $R^2$ ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2: \", mco1.rsquared)\n",
    "print(\"R2 Ajustado: \", mco1.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-cuadrado ($R^2$): Es una medida de la bondad de ajuste del modelo. Un valor de 0.8392687264616815(o aproximadamente 83.93%) significa que aproximadamente el 83.93% de la variabilidad en la variable dependiente es explicada por las variables independientes en el modelo.\n",
    "\n",
    "R-cuadrado ajustado: Es una versión ajustada del R-cuadrado que tiene en cuenta el número de predictores en el modelo. Un valor de 0.8367131041747956 es bastante similar al R-cuadrado, lo que indica que el modelo es robusto incluso después de ajustar por el número de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valor ( F<sub>exp</sub> ): Valor F experimental\n",
    "- Valor ( F<sub>teo</sub> ): Valor F teórico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fexp = mco1.fvalue\n",
    "print(Fexp)\n",
    "from scipy import stats\n",
    "\n",
    "alpha = 0.025\n",
    "Fteo = stats.f.ppf(1 - alpha, mco1.df_model, mco1.df_resid)\n",
    "print(Fteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor F experimental (Fexp): Es el valor calculado de la estadística F para el modelo. Un valor de 328.40092636864495 es bastante alto, lo que sugiere que el modelo es estadísticamente significativo.\n",
    "\n",
    "Valor F teórico (Fteo): Es el valor crítico de la distribución F para un cierto nivel de significancia y grados de libertad. Un valor de 1.2941958816630579 es el umbral sobre el cual se consideraría que el modelo tiene una contribución significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valor ( t<sub>exp</sub> ): Valor t experimental\n",
    "- Valor ( t<sub>teo</sub> ): Valor t teórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texp = mco1.tvalues\n",
    "print(texp)\n",
    "alpha = 0.098\n",
    "tteo = stats.t.ppf(1 - (alpha / 2), mco1.df_resid)\n",
    "print(tteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Valor t Experimental (Valor t de la Prueba): Este valor es el resultado de una prueba t de student aplicada a un estimador, como un coeficiente en un modelo de regresión. Se calcula como el coeficiente estimado dividido por el error estándar de ese coeficiente. En el contexto de la regresión, indica cuántas desviaciones estándar el estimador está lejos de 0. Un valor t alto (en valor absoluto) sugiere que es menos probable que el verdadero valor del parámetro sea 0, lo que implica que la variable correspondiente es significativa en el modelo.\n",
    "\n",
    "Valor t Teórico (Valor t Crítico): Se utiliza como umbral para decidir si rechazar la hipótesis nula. Si el valor t experimental es mayor en valor absoluto que el valor t teórico, se rechaza la hipótesis nula (por ejemplo, que un coeficiente es igual a cero en la regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intervalos de confianza de Estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.conf_int(0.075))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un intervalo de confianza ofrece un rango de valores dentro del cual se espera que se encuentre el verdadero valor del parámetro, con un cierto nivel de confianza.\n",
    "En la regresión, cada coeficiente tiene un intervalo de confianza asociado. Si un intervalo de confianza para un coeficiente no incluye el 0, esto sugiere que la variable correspondiente es significativamente diferente de 0, lo que implica que tiene un efecto significativo en la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimación de la varianza de la pertrubación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3 = np.array(mco1.params)\n",
    "e = mco1.resid\n",
    "sum(e ** 2) / (mco1.nobs - 1)\n",
    "sigmagorro = (np.dot(y.values, y.values) - np.dot(beta3.T, np.dot(X.values.T, y.values))) / (mco1.nobs - 1)\n",
    "\n",
    "print(sigmagorro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor bajo indica que el modelo explica una gran parte de la variabilidad, mientras que un valor alto sugiere que hay más factores no capturados que influyen en los salarios.\n",
    "En nuestro caso vemos que el valor es alto y que los residuos no se distribuyen normalmente, puede ser necesario transformar las variables, agregar términos al modelo o utilizar otro tipo de modelo de regresión que no requiera la normalidad de los residuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto anteriormente nuestro modelo actual tiene un problema de multicolinealidad que trataremos de solucionar ahora. Refresquemos la memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como hemos mencionado nos advierte de posible multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un número de condición alto sugiere una posible multicolinealidad en los datos, lo que significa que al menos una de las variables predictoras es casi una combinación lineal de las otras. Esto puede llevar a problemas en la estimación de los coeficientes del modelo, ya que pequeños cambios en los datos o en el modelo pueden resultar en grandes cambios en los coeficientes estimados. En términos prácticos, un número de condición alto puede hacer que los resultados de la regresión sean poco fiables.\n",
    "\n",
    "En términos generales:\n",
    "\n",
    "Un número de condición cercano a 1 indica un problema bien condicionado (bajo riesgo de multicolinealidad).\n",
    "Un número de condición moderadamente alto (valores de miles o decenas de miles) puede ser motivo de cierta preocupación y merece una investigación más detallada.\n",
    "Un número de condición muy alto (valores en los cientos de miles o más) sugiere un alto grado de multicolinealidad y un problema potencialmente mal condicionado.\n",
    "\n",
    "En nuestro caso vemos como este es un número enorme, posiblemente debido a los dummies que al crear 200 variables distintas produzcan este error.\n",
    "Por ello vamos a emplear técnicas como el factor de inflación de la varianza (VIF) para identificar y posiblemente eliminar variables independientes que estén altamente correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], dtype=int)\n",
    "\n",
    "display(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el warning \"RuntimeWarning: divide by zero encountered in scalar divide\" sugiere que en el cálculo de algún VIF, se está intentando dividir por cero. Esto suele suceder cuando una de las variables independientes en el modelo de regresión es una combinación lineal perfecta de otras variables independientes, o tiene una varianza extremadamente baja que está causando problemas numéricos.\n",
    "\n",
    "Los valores de VIF se muestran en la salida, y muchos de ellos son inf, que significa infinito. Un valor de VIF infinito indica una multicolinealidad perfecta, lo que significa que algunas variables predictoras pueden ser exactamente predichas a partir de otras variables predictoras en el modelo sin error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es bastante evidente cuál podría ser el primer remedio para este problema... Reducir el número de variables, esto se conseguirá estudiando que variables no tienen relevancia para eliminarlas y agrupando las que sí sean positivas para el modelo.\n",
    "\n",
    "Hagamos una primera prueba muy sencilla solo añadiendo drop_first=True a la hora de crear los dummies para eliminar la primera columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])\n",
    "\n",
    "mco1 = sm.OLS(y, X).fit()\n",
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplemente con ese paso previo hemos pasado de un Número de Condición = (4.75e+16) que tenía nuestro modelo original a un Número de Condición = (2.94e+03)\n",
    "\n",
    "Y volvemos a ejecutar la técnica VIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver ya prácticamente todas las variables están cerca del valor 1 que como hemos visto indica un problema bien condicionado (bajo riesgo de multicolinealidad).\n",
    "\n",
    "Pero podemos seguir depurándolo. Si nos fijamos hay 2 variables en concreto que resaltan más que las demás, la primera con valor aproximado de 148.191 y la antepenúltima con valor aproximado de 11.852499\n",
    "\n",
    "Viendo esto y además con un poco de sentido común podemos razonar que a la hora de estimar salarios tanto la edad como el género de la persona no debería de ser un factor influyente en el resultado así que eliminemos esas 2 variables y veamos que pasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "\n",
    "#datos.drop('Job Title_Data Analyst', axis=1, inplace=True)\n",
    "#datos.drop('Job Title_Marketing Manager', axis=1, inplace=True)\n",
    "#datos.drop('Job Title_Web Developer', axis=1, inplace=True)\n",
    "\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "#X = sm.add_constant(datos[education_columns + job_columns])\n",
    "#X = sm.add_constant(datos[education_columns + ['Years of Experience']])\n",
    "\n",
    "mco1 = sm.OLS(y, X).fit()\n",
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, al eliminar variables que no tienen una relación directa con el salario el Número de Condición = (2.94e+03) que tenía nuestro modelo con Edad y Género se ha reducido a tan solo un Número de Condición = 834 sin sacrificar la medida de bondad R^2^\n",
    "\n",
    "Ya no nos advierte de que pueda haber problemas de multicolinealidad, pero probemos a reducir el número de variables agrupando elementos de la variable Job Title por sectores, esto puede llevar a estimaciones más imprecisas al tener datos más generales de cada ámbito pero probemos a ver que Número de Condición resultaría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:<br><br></strong> Se puede probar quitando los '#' que he puesto en la celda de arriba\n",
    "    <br><br>\n",
    "    Eliminando la variable 'Years of Experience' el Nº de Cond. pasa de 833.5492 a 89.2, pero $R^2$ se ve afectado en un decremento de 0.838 a 0.680\n",
    "    <br><br>\n",
    "    Eliminando la variable 'job_columns' el Nº de Cond. pasa de 833.5492 a 43.8, pero $R^2$ se ve afectado en un decremento de 0.838 a 0.709\n",
    "    <br><br>\n",
    "    Los comandos datos.drop no son necesarios pero están porque pueden reducir el valor de los índices VIF. Simplemente eliminan más columnas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para esta siguiente prueba he creado un duplicado de la base de datos, pero he reducido significativamente el número de variables, especialmente de la columna Job Titles en el que he agrupado distintas categorías en una**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data - Copy.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Como vemos esta reducción/agrupación de los datos nos ha vuelto a reducir el N.º de Condición de 834 a 213**\n",
    "\n",
    "**Además, todo esto ha sido posible sin sacrificar la bondad del ajuste que sigue siendo bastante buena, dando así por solucionado el problema de la multicolinealidad**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heterocedatiscidad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Anteriormente, hemos tratado la multicolinealidad, ahora vamos a comprobar si nuestro modelo sigue una distribución normal de los residuos (homocedasticidad) o no (heterocedasticidad).**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera Est', 'Jarque-Vera p-val', 'Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(mco1.resid)\n",
    "for i in range(4):\n",
    "    print(name[i], test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El estadístico de Jarque-Bera es 187.68, lo cual es muy alto. Este test combina la asimetría y la curtosis para evaluar si la distribución de los residuos se desvía de la normalidad. Un valor más alto indica una mayor desviación de la normalidad.\n",
    "\n",
    "- El valor p asociado con el estadístico de Jarque-Bera es extremadamente pequeño (alrededor de 1.76e-41). Un valor p tan bajo indica que podemos rechazar la hipótesis nula de que los residuos tienen una distribución normal.\n",
    "\n",
    "- La asimetría de los residuos es -0.1125, lo que indica una leve asimetría hacia la izquierda. Sin embargo, este valor está bastante cerca de cero, lo que sugiere que la asimetría no es muy pronunciada.\n",
    "\n",
    "- La curtosis es 3.7960, que es ligeramente mayor que el valor de 3 que se esperaría de una distribución normal. Esto indica que la distribución de los residuos tiene colas ligeramente más pesadas que una distribución normal, aunque este valor no es muy lejano de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "pyplot.hist(mco1.resid)\n",
    "pyplot.show()\n",
    "qqplot(mco1.resid, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diag.kstest_normal(mco1.resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El primer valor (0.0676) es el estadístico D de Kolmogorov-Smirnov, que mide la distancia máxima entre la función de distribución acumulativa (CDF) de los residuos y la CDF de una distribución normal. Un valor más alto indica una mayor desviación de la normalidad.\n",
    "\n",
    "- El segundo valor (aproximadamente 0.0) es el valor p del test. Como es menor que cualquier umbral comúnmente usado para significancia estadística (como 0.05 o 0.01), se rechaza la hipótesis nula de que la distribución de los residuos es normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "\n",
    "y = datos['Salary']\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*' y 'Years of Experience'\n",
    "# Filtrar las columnas que comienzan con 'Education Level_'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "\n",
    "from random import choices\n",
    "\n",
    "beta = []\n",
    "n = len(y)\n",
    "for it in range(100):  #repetimos 100 veces la estimacion\n",
    "    I = choices(list(range(n)), k=n)  # elegimos una muestra con repeticion de los datos\n",
    "    mco3 = sm.OLS(y[I], sm.add_constant(X.values[I, :])).fit()  #ajustamos el modelo\n",
    "    beta.append(list(mco3.params))  # guardamos los coeficientes\n",
    "beta = np.array(beta)\n",
    "k = len(X.T)\n",
    "for i in range(k):\n",
    "    q025 = np.percentile(beta[:, i], 2.5)  #percentil 2.5%\n",
    "    q975 = np.percentile(beta[:, i], 97.5)  #percentil 97.5%\n",
    "    media = np.mean(beta[:, i])  #media de los betas\n",
    "    sd = np.std(beta[:, i])  #desviación tipica de los betas\n",
    "    print(i, media, [q025, q975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializa una lista vacía beta para almacenar los resultados de los coeficientes de las simulaciones de bootstrapping.\n",
    "Realiza 1000 iteraciones de bootstrapping. En cada iteración:\n",
    "- Selecciona una muestra aleatoria con reemplazo de los índices de los datos (esto simula el remuestreo de los datos).\n",
    "- Ajusta un modelo de regresión lineal a la muestra remuestreada.\n",
    "- Guarda los coeficientes estimados del modelo en la lista beta.\n",
    "\n",
    "Los percentiles calculados representan los límites del intervalo de confianza del 95% para los coeficientes, basado en la distribución de bootstrapping.\n",
    "La finalidad de este proceso es estimar la distribución de los coeficientes del modelo de regresión más allá de lo que el modelo ajustado a los datos originales puede proporcionar. El bootstrapping es especialmente útil cuando la distribución de los estimadores no es conocida o es difícil de derivar analíticamente. Los intervalos de confianza calculados a partir de la distribución de bootstrapping pueden proporcionar una medida robusta de la incertidumbre en las estimaciones de los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Years of Experience\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.910836799262646 es el estadístico de prueba de Goldfeld-Quandt.\n",
    "- 0.9855773263736483 es el valor p de la prueba.\n",
    "Dado que el valor p es alto, no hay evidencia suficiente para rechazar la hipótesis nula de homocedasticidad, lo que significa que no hay evidencia de heterocedasticidad en los datos según esta prueba, por tanto, seguiremos probando con otras variables y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Data Scientist\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Software Engineer\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Product Manager\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_PhD\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt PhD: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_Master\\'s Degree\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt Master: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_High School\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt HS: \", GQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con algunas pruebas más observamos como el valor de p de 'Education Level_High School' es minúsculo. Un valor p por debajo de un nivel de significancia común (como 0.05 o 0.01) indica que hay suficiente evidencia para rechazar la hipótesis nula de que la varianza de los residuos es constante a lo largo del rango de los datos, es decir, que hay heterocedasticidad. Sin embargo, para confirmar la hipótesis ratifiquémosla con otras técnicas de detección de heterocedasticidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREUSH-PAGAN\n",
    "BP = sms.het_breuschpagan(mco1.resid, mco1.model.exog)\n",
    "print(\"Breush Pagan: \", BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHITE\n",
    "W = sms.het_white(mco1.resid, mco1.model.exog)\n",
    "print(\"White: \", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En ambos casos, los valores p reportados son 0.0, lo que indica que hay evidencia estadística significativa para rechazar la hipótesis nula de que los errores son homocedásticos (tienen varianzas constantes). Esto significa que los resultados de ambas pruebas apuntan a la presencia de heterocedasticidad en los residuos del modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLEJSER\n",
    "for h in [-2, -1, -0.5, 0.5, 1, 2]:\n",
    "    # Asegúrate de que no haya ceros en los datos antes de elevar a una potencia negativa\n",
    "    X_nonzero = X.replace(0, np.nan)  # Reemplaza 0 por NaN para evitar divisiones por cero\n",
    "    X_transformed = X_nonzero.astype(float) ** h  # Eleva a la potencia de h\n",
    "    X_transformed = X_transformed.fillna(0)  # Reemplaza NaNs con 0s si es necesario, dependiendo del contexto\n",
    "    X_transformed = X_transformed.replace([np.inf, -np.inf], np.nan)  # Reemplaza inf por NaN\n",
    "    X_transformed = X_transformed.dropna(axis=1, how='all')  # Elimina las columnas donde todos los valores son NaN\n",
    "\n",
    "    mcoaux = sm.OLS(abs(mco1.resid), sm.add_constant(X_transformed)).fit()\n",
    "    beta3 = mcoaux.params\n",
    "    pval = beta3.iloc[1]\n",
    "    print(\"h: \", h, \"-> pval:\", pval, \"R2: \", mcoaux.rsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:</strong> El test de Glejser es un método utilizado para detectar heterocedasticidad en los errores de un modelo de regresión. Específicamente busca relaciones entre los valores absolutos de los residuos de un modelo de regresión y las variables independientes o transformaciones de estas variables. Si existe una relación significativa, sugiere que la varianza de los errores cambia con el nivel de la variable independiente, lo cual es una forma de heterocedasticidad.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para h= −2, el valor p es muy pequeño, lo que sugiere que hay una relación significativa entre los residuos y las variables independientes elevadas a la potencia de -2, indicando heterocedasticidad.\n",
    "Este patrón se repite para otros valores de h, con valores p muy pequeños, lo que indica que la heterocedasticidad es detectada consistentemente para varias transformaciones de las variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = sm.WLS(y, sm.add_constant(X), weights=1 / y).fit()\n",
    "print(mcp.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viendo que con mco1 no estamos obteniendo las mejores en heterocedasticidad que queremos ni aplicando otros modelos de regresión como la de por mínimos cuadrados ponderados (WLS) probemos con una variante de la regresión por minimos cuadrados ordinarios que llamaremos mco2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresquemos la memoria sobre mco2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data - Copy.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "y = datos['Salary']\n",
    "\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*' y 'Years of Experience'\n",
    "# Filtrar las columnas que comienzan con 'Education Level_'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[['Years of Experience'] + job_columns + education_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREUSH-PAGAN\n",
    "BP = sms.het_breuschpagan(mco2.resid, mco2.model.exog)\n",
    "print(\"Breush Pagan: \", BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHITE\n",
    "W = sms.het_white(mco2.resid, mco2.model.exog)\n",
    "print(\"White: \", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(mco2.resid)\n",
    "print(dw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aunque hay una mejora en mco2 respecto a mco1 vemos que las pruebas siguen indicando presencia de heterocedasticidad, aparte vemos en el factor Durbin-Watson que tenemos problemas de autocorrelación al estar este alejado de 2**\n",
    "\n",
    "**En resumen: aún tenemos problemas de heterocedasticidad y autocorrelación. Estos serán solucionados a continuación**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Depuración de los datos para MCO2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "datos = pd.read_csv('Salary_Data - Copy2.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "\n",
    "#y, lambda_opt = boxcox((datos['Salary']))\n",
    "#y = np.log(datos['Salary'])\n",
    "y = np.sqrt(datos['Salary'])\n",
    "\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[['Years of Experience'] + job_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analizando nuevamente el resumen del modelo podemos apreciar como por fin hemos conseguido reducir el valor Jarque-Bera a valores bajos, esto se ha conseguido eliminando más variables que no aportaban al modelo como 'Education Level' y empleando transformaciones a la variable dependiente. A base de probar, hemos averiguado que la transformación óptima en nuestro caso es por raíz cuadrada, dejamos comentada para probar la transformación por logaritmos y boxcos. También cabe destacar que creamos una nueva copia de los datos llamada 'Salary_Data - Copy2.csv' en el que depuramos aún más los datos, agrupando cada puesto a su departamento.**\n",
    "\n",
    "- Skew: Un valor de 0.010 indica que la distribución de los residuos es muy simétrica.\n",
    "- Kurtosis: Un valor de 3.094 es muy cercano a 3, que es la kurtosis de una distribución normal, indicando una forma de distribución de los residuos razonablemente normal.\n",
    "- Jarque-Bera (JB): Un valor bajo de 2.045 y un valor p de 0.360 sugieren que no hay evidencia suficiente para rechazar la hipótesis de normalidad de los residuos, con lo que ya hemos resuelto el problema de heterocedasticidad.\n",
    "\n",
    "**En resumen, los residuos del modelo parecen estar distribuidos de manera relativamente normal basándose en la prueba Jarque-Bera, dando por concluido así nuestra optimización del modelo en términos de heterocedasticidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(mco2.resid)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como el valor de Durbin-Watson ha pasado a ser aproximadamente 2.0238536 respecto a su versión anterior que era aproximadamente 0.20593535621886824 y como ya sabemos un valor cercano a 2 sugiere que NO hay autocorrelación.\n",
    "\n",
    "Este problema ha sido solucionado simplemente randomizando los datos de la base de datos, ya que al estar manipulándolos previamente los habíamos ordenado y estaban serializados en torno a una de sus variables. Para mantener todo el proceso anterior y ver la evolución del modelo hemos creado una base de datos aparte que es la que se utiliza arriba y la que hemos llamado 'Salary_Data - Copy2.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusiones Finales:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. **Significancia de los Predictores:**\n",
    "- Los años de experiencia y los puestos de trabajo específicos han demostrado ser predictores significativos de los salarios, lo que indica que ambos factores son importantes al determinar la compensación de un empleado.\n",
    "- Los coeficientes de regresión para los distintos puestos de trabajo reflejan las diferencias salariales entre las profesiones, ajustadas por la experiencia laboral.\n",
    "\n",
    "2. **Ajuste del Modelo:**\n",
    "- El modelo muestra un buen ajuste general, con un R-cuadrado ajustado que indica que una proporción sustancial de la variabilidad en los salarios se puede explicar con las variables incluidas en el modelo.\n",
    "- Los diagnósticos de residuos sugieren que la asunción de normalidad se mantiene razonablemente bien y aunque hubo indicaciones de autocorrelación y heterocedasticidad, estas pudieron corregirse.\n",
    "\n",
    "3. Diagnóstico de Multicolinealidad:\n",
    "- Se descubrió una multicolinealidad altísima debida al gran número de variables iniciales en los datos (+200).\n",
    "- Se realizaron 2 depuraciones sobre los datos que redujeron drásticamente el N.º de condición y redujo enormemente la multicolinealidad.\n",
    "\n",
    "4. **Diagnóstico de Heterocedasticidad:**\n",
    "- Se detectó heterocedasticidad en los residuos, lo que llevó a aplicar transformaciones y el uso de errores estándar robustos para corregir las inferencias estadísticas.\n",
    "- Se aplicaron transformaciones como la raíz cuadrada, logarítmicas y de Box-Cox para estabilizar la varianza de los residuos y corregir la heterocedasticidad, concluyendo como más óptima la raíz cuadrada.\n",
    "\n",
    "6. **Diagnóstico de Autocorrelación:**\n",
    "- Se encontraron signos de autocorrelación en los residuos, que resulto ser un error en los datos que estaban serializados en torno a una de sus variables consecuencia de la depuración de estos.\n",
    "- Para solucionarlo solo se tuvo que randomizar los datos de nuevo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIN**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
