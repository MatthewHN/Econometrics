{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Estimator for Tech Positions in the USA\n",
    "### Made by:\n",
    "- Matthew Samuel Horne Negro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I have chosen a Kaggle Database on the salaries earned by employees in job positions in the USA. I believe that analyzing this data can be interesting, even for personal benefit, as some friends and even myself are considering the possibility of going overseas to work. The data is specifically selected from companies in the Tech sector, although, as we will see, there are positions in Marketing and Human Resources, all of these are from technological companies.**\n",
    "\n",
    "**The Database collects data from a sample of over 6500 employees, for whom the following information is provided:**\n",
    "\n",
    "Age\n",
    "Gender\n",
    "Level of education\n",
    "Job position\n",
    "Years of experience in the position\n",
    "Salary\n",
    "\n",
    "**In this model, we will attempt to estimate an employee's salary based on the rest of the variables.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First econometrics models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import statsmodels.stats.outliers_influence as oi\n",
    "import statsmodels.graphics.api as smg\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.stats.diagnostic as diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, I like to have all the imports together and not have to repeat them or execute specific cells to avoid compiling the entire notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Salary_Data.csv')\n",
    "\n",
    "X = data.values[:, [0, 4]].astype(int)  # Age, Years of Experience\n",
    "Y = data.values[:, 5].astype(int)  # Salary\n",
    "\n",
    "results = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared:**\n",
    "\n",
    "R-squared is a measure of how well the regression model fits the data. In this case, the value is 0.665, meaning that approximately 66.5% of the variability in the dependent variable (y) can be explained by the independent variables (x1 and x2) in the model. A higher R-squared value indicates a better fit of the model to the data. This value is expected to increase as the model becomes more complex and incorporates more key variables like Job Title or Education.\n",
    "\n",
    "**Adjusted R-squared:**\n",
    "\n",
    "Adjusted R-squared is similar to R-squared but takes into account the number of independent variables in the model. Here, the value is also 0.665, suggesting that the model's fit is consistent with the number of independent variables included.\n",
    "\n",
    "**F-statistic:**\n",
    "\n",
    "The F-statistic is used to evaluate the overall significance of all the independent variables in the model. A large F-statistic value (in this case, 6539) with a small p-value (0.00) suggests that at least one of the independent variables significantly explains variability in the dependent variable.\n",
    "\n",
    "**Coefficients:**\n",
    "\n",
    "Under the \"coef\" section, the estimated coefficients for the variables in the model are observed. In this model, there are three coefficients: one for the constant (intercept), one for x1, and another for x2. These coefficients indicate how much the dependent variable (y) changes per unit change in the independent variables (x1 and x2). For instance, the coefficient for x2 is 9044.7257, implying that, all other variables being constant (ceteris paribus), an increase of one unit in x2 is associated with an approximate increase of 9044.7257 units in the dependent variable (y), meaning that for every additional year of experience (Years of Experience = x2), the salary (Salary = y) increases by 9044.7257$.\n",
    "\n",
    "**Additional Statistics:**\n",
    "\n",
    "Several additional statistics are provided, such as the Omnibus, Durbin-Watson, Jarque-Bera, Skew, and Kurtosis. These statistics help evaluate assumptions about the model and the normality of the residual errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Note: </strong> Since we are using a database with variables that are of string type, for this first model we will only use numeric variables and which have had to be necessarily converted to int because otherwise, it will generate a type error.\n",
    "    <br><br>\n",
    "    Later on, it will be necessary to convert the categorical variables into dummies for the correct functioning.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Test model (not related to the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "X = np.random.normal(0, 10, n)\n",
    "Y = X + np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte = results.params[0]\n",
    "beta1 = results.params[1]\n",
    "\n",
    "plt.plot([-20, 20], [cte + beta1 * (-20), cte + beta1 * 20], color='r')\n",
    "plt.scatter(X, Y, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code blocks perform a simulation of data and fit a linear regression model to such data.\n",
    "\n",
    "1. **Data Generation:** Two datasets, X and Y, are created, where X are values taken from a normal distribution with a mean of 0 and standard deviation of 10, and Y is a linear function of X plus a normally distributed random error term. This simulates a linear relationship between X and Y with some noise.\n",
    "\n",
    "2. **Data Visualization:** A scatter plot is generated using matplotlib to visualize the relationship between X and Y. Each point represents an observation from the simulated dataset.\n",
    "\n",
    "3. **Fitting of Regression Model:** An ordinary least squares linear regression model is fitted using statsmodels with Y as the dependent variable and X as the independent. A constant is added to the model to include an intercept term. A summary of the model is printed, providing statistical details of the fit.\n",
    "\n",
    "4. **Visualization of Regression Model:** The intercept and slope (coefficients) from the fitted model are extracted and used to draw the regression line over the existing scatter plot. The red line represents the estimated relationship between X and Y according to the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation and Inference in Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Salary_Data.csv')\n",
    "\n",
    "# Muestra estadísticas descriptivas de las variables numéricas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Count:** Displays the total number of non-null entries for each variable.\n",
    "   - In this case, there are 6582 entries for each of the variables: Age, Years of Experience, and Salary.\n",
    "\n",
    "2. **Mean:** It is the average of the values for each variable.\n",
    "   - The average age is approximately 33.57 years.\n",
    "   - The average years of experience are approximately 8.07 years.\n",
    "   - The average salary is approximately 115,768.67 monetary units ($).\n",
    "\n",
    "3. **Std (Standard Deviation):** Measures the amount of variation or dispersion of a set of values.\n",
    "   - The standard deviation of age is approximately 7.6 years, indicating the variability of age in the dataset.\n",
    "   - The standard deviation of years of experience is approximately 6.04 years.\n",
    "   - The standard deviation of the salary is approximately 52,677.91, indicating the variability in salaries.\n",
    "\n",
    "4. **Min (Minimum):** It is the lowest value in each column.\n",
    "   - The minimum age is 21 years.\n",
    "   - The minimum years of experience is 0 (people with no prior experience).\n",
    "   - The minimum salary is 25,000.\n",
    "\n",
    "5. **25% (25th Percentile):** This is the value below which 25% of the data falls.\n",
    "   - 25% of the employees are 28 years or younger.\n",
    "   - 25% have 3 years or less of experience.\n",
    "   - 25% earn 70,000 or less.\n",
    "\n",
    "6. **50% (Median or 50th Percentile):** It is the median value, where half of the data is below this value and the other half above.\n",
    "   - The median age is 32 years.\n",
    "   - The median years of experience is 7 years.\n",
    "   - The median salary is 115,000.\n",
    "\n",
    "7. **75% (75th Percentile):** The value below which 75% of the data falls.\n",
    "   - 75% of the employees are 38 years or younger.\n",
    "   - 75% have 12 years or less of experience.\n",
    "   - 75% earn 160,000 or less.\n",
    "\n",
    "8. **Max (Maximum):** It is the highest value in each column.\n",
    "   - The maximum age is 62 years.\n",
    "   - The maximum years of experience is 34 years.\n",
    "   - The maximum salary is 250,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], dtype=int)\n",
    "\n",
    "display(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> I have spent hours stuck creating dummies; when creating dummies by default, the types are set to TRUE or FALSE, however, we only work with numbers so, after hours I found out that it only needed to be cast to int type (dtype=int).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['Salary']\n",
    "\n",
    "# Filtrar las columnas que comienzan con 'Education Level_*', 'Job Title_*' y 'Gender_*'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*', 'Job Title_*' y 'Gender_*' + 'Years of Experience' y 'Age'\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = np.mean(y)\n",
    "Q1 = np.quantile(y, 0.25)\n",
    "Q3 = np.quantile(y, 0.75)\n",
    "DesviacionTipica = np.std(y)\n",
    "Mediana = np.median(y)\n",
    "histograma = plt.hist(y, bins='auto', rwidth=0.85, density=True)\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(\"Histograma de y (salary) ($)\")\n",
    "plt.show()\n",
    "print(\"Q1: \", Q1, \"($) Mediana:\", Mediana, \"($) Q3: \", Q3, \"($) DT: \", DesviacionTipica, \"($) Media:\", np.mean(y),\n",
    "      \"($)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mean: 115,768.67\n",
    "2. First Quartile (Q1): 70,000.00\n",
    "3. Third Quartile (Q3): 160,000.00\n",
    "4. Standard Deviation: 52,673.91\n",
    "5. Median: 115,000.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.asarray(education_columns)\n",
    "ols1 = sm.OLS(y, X).fit()\n",
    "print(ols1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> As we can see, we are already being warned that there may be multicollinearity problems; we will try to solve it later on when the time comes, perhaps with a manual cleaning of the data or using techniques such as the variance inflation factor (VIF) to identify and possibly eliminate independent variables that are highly correlated.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Results\n",
    "\n",
    "#### Goodness of Fit Measures:\n",
    "\n",
    "- **R-squared:**\n",
    "    The value is 0.839, which indicates that approximately 83.9% of the variability in the salary can be explained by the model. This is a quite high measure of goodness of fit considering that we are trying to estimate salaries.\n",
    "\n",
    "- **Adjusted R-squared:**\n",
    "    With a value of 0.837, after adjusting for the number of predictors, it remains very high, indicating that the model fits well to the data.\n",
    "\n",
    "- **F-statistic:**\n",
    "    With a value of 328.4 and a Prob (F-statistic) close to 0, it suggests that the model is statistically significant as a whole, that is, there is evidence that at least one of the independent variables is related to the salary.\n",
    "\n",
    "#### Residual Diagnostics:\n",
    "- **Durbin-Watson:**\n",
    "    The value is 0.216, which is well below 2, suggesting the presence of positive autocorrelation among the residuals, which could be a problem since the residuals of a well-fitted model should be independent of each other.\n",
    "\n",
    "- **Jarque-Bera (JB) and Prob(JB):**\n",
    "    The JB statistic value is 178.435 and the p-value is extremely small, indicating that the residuals do not follow a normal distribution, which is a violation of one of the assumptions of OLS regression.\n",
    "\n",
    "- **Skew:**\n",
    "    The value of -0.062 indicates that the distribution of residuals is slightly asymmetrical, but it is not a major concern given that it is close to zero.\n",
    "\n",
    "- **Kurtosis:**\n",
    "    A value of 3.797 suggests that the distribution of the residuals has heavier tails than a normal distribution, which could be a sign of outliers or a more pronounced peak.\n",
    "\n",
    "- **Cond. No. (Condition Number):**\n",
    "    The value is extremely high (4.75e+16), indicating the presence of multicollinearity among the predictor variables. This means that some of the independent variables are highly correlated with each other, which can inflate the standard errors of the coefficients and make the estimates unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2 = ols1.params\n",
    "plt.plot(datos['Years of Experience'], y, 'o', color='r')\n",
    "xmin = np.min(datos['Years of Experience'])\n",
    "xmax = np.max(datos['Years of Experience'])\n",
    "\n",
    "plt.plot([xmin, xmax], [beta2.iloc[0] + beta2.iloc[1] * xmin, beta2.iloc[0] + beta2.iloc[1] * xmax])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.graphics.plot_regress_exog(ols1, 'Years of Experience'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ols1.resid\n",
    "print(e)\n",
    "print(np.mean(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained value suggests that, on average, the model slightly underestimates the actual value. However, in the context of regression models, an average of residuals of about -5.7624e-10 could be considered negligible, especially if the scale of the response variable (salary in this case) is large, as in tens or hundreds of thousands. This result is a sign that the model is well-calibrated in terms of not having a systematic bias towards overestimation or underestimation in the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total Sum of Squares (SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.centered_tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It represents the total variability in the dependent variable. It is equal to the sum of the squared differences between each observed value and the mean of all observed values. A value of 18262027724544.66 indicates the total variability in your dependent variable that the model seeks to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explained Sum of Squares (ESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.ess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents the variability in the dependent variable that is explained by the model. It is equal to the sum of the squared differences between the predicted values by the model and the mean of the dependent variable. A value of 15326748750986.516 suggests that this is the amount of variability that the model has managed to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Residual Sum of Squares (RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents the variability in the dependent variable that is not explained by the model. It is equal to the sum of the squares of the residuals (errors) from the model. A value of 2935278973558.1436 indicates the amount of variability that the model has not been able to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $R^2$ and Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2: \", mco1.rsquared)\n",
    "print(\"R2 Ajustado: \", mco1.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-cuadrado ($R^2$): Es una medida de la bondad de ajuste del modelo. Un valor de 0.8392687264616815(o aproximadamente 83.93%) significa que aproximadamente el 83.93% de la variabilidad en la variable dependiente es explicada por las variables independientes en el modelo.\n",
    "\n",
    "R-cuadrado ajustado: Es una versión ajustada del R-cuadrado que tiene en cuenta el número de predictores en el modelo. Un valor de 0.8367131041747956 es bastante similar al R-cuadrado, lo que indica que el modelo es robusto incluso después de ajustar por el número de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valor ( F<sub>exp</sub> ): Valor F experimental\n",
    "- Valor ( F<sub>teo</sub> ): Valor F teórico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fexp = mco1.fvalue\n",
    "print(Fexp)\n",
    "from scipy import stats\n",
    "\n",
    "alpha = 0.025\n",
    "Fteo = stats.f.ppf(1 - alpha, mco1.df_model, mco1.df_resid)\n",
    "print(Fteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor F experimental (Fexp): Es el valor calculado de la estadística F para el modelo. Un valor de 328.40092636864495 es bastante alto, lo que sugiere que el modelo es estadísticamente significativo.\n",
    "\n",
    "Valor F teórico (Fteo): Es el valor crítico de la distribución F para un cierto nivel de significancia y grados de libertad. Un valor de 1.2941958816630579 es el umbral sobre el cual se consideraría que el modelo tiene una contribución significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valor ( t<sub>exp</sub> ): Valor t experimental\n",
    "- Valor ( t<sub>teo</sub> ): Valor t teórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texp = mco1.tvalues\n",
    "print(texp)\n",
    "alpha = 0.098\n",
    "tteo = stats.t.ppf(1 - (alpha / 2), mco1.df_resid)\n",
    "print(tteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Valor t Experimental (Valor t de la Prueba): Este valor es el resultado de una prueba t de student aplicada a un estimador, como un coeficiente en un modelo de regresión. Se calcula como el coeficiente estimado dividido por el error estándar de ese coeficiente. En el contexto de la regresión, indica cuántas desviaciones estándar el estimador está lejos de 0. Un valor t alto (en valor absoluto) sugiere que es menos probable que el verdadero valor del parámetro sea 0, lo que implica que la variable correspondiente es significativa en el modelo.\n",
    "\n",
    "Valor t Teórico (Valor t Crítico): Se utiliza como umbral para decidir si rechazar la hipótesis nula. Si el valor t experimental es mayor en valor absoluto que el valor t teórico, se rechaza la hipótesis nula (por ejemplo, que un coeficiente es igual a cero en la regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intervalos de confianza de Estimadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.conf_int(0.075))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un intervalo de confianza ofrece un rango de valores dentro del cual se espera que se encuentre el verdadero valor del parámetro, con un cierto nivel de confianza.\n",
    "En la regresión, cada coeficiente tiene un intervalo de confianza asociado. Si un intervalo de confianza para un coeficiente no incluye el 0, esto sugiere que la variable correspondiente es significativamente diferente de 0, lo que implica que tiene un efecto significativo en la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimación de la varianza de la pertrubación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3 = np.array(mco1.params)\n",
    "e = mco1.resid\n",
    "sum(e ** 2) / (mco1.nobs - 1)\n",
    "sigmagorro = (np.dot(y.values, y.values) - np.dot(beta3.T, np.dot(X.values.T, y.values))) / (mco1.nobs - 1)\n",
    "\n",
    "print(sigmagorro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor bajo indica que el modelo explica una gran parte de la variabilidad, mientras que un valor alto sugiere que hay más factores no capturados que influyen en los salarios.\n",
    "En nuestro caso vemos que el valor es alto y que los residuos no se distribuyen normalmente, puede ser necesario transformar las variables, agregar términos al modelo o utilizar otro tipo de modelo de regresión que no requiera la normalidad de los residuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto anteriormente nuestro modelo actual tiene un problema de multicolinealidad que trataremos de solucionar ahora. Refresquemos la memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como hemos mencionado nos advierte de posible multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un número de condición alto sugiere una posible multicolinealidad en los datos, lo que significa que al menos una de las variables predictoras es casi una combinación lineal de las otras. Esto puede llevar a problemas en la estimación de los coeficientes del modelo, ya que pequeños cambios en los datos o en el modelo pueden resultar en grandes cambios en los coeficientes estimados. En términos prácticos, un número de condición alto puede hacer que los resultados de la regresión sean poco fiables.\n",
    "\n",
    "En términos generales:\n",
    "\n",
    "Un número de condición cercano a 1 indica un problema bien condicionado (bajo riesgo de multicolinealidad).\n",
    "Un número de condición moderadamente alto (valores de miles o decenas de miles) puede ser motivo de cierta preocupación y merece una investigación más detallada.\n",
    "Un número de condición muy alto (valores en los cientos de miles o más) sugiere un alto grado de multicolinealidad y un problema potencialmente mal condicionado.\n",
    "\n",
    "En nuestro caso vemos como este es un número enorme, posiblemente debido a los dummies que al crear 200 variables distintas produzcan este error.\n",
    "Por ello vamos a emplear técnicas como el factor de inflación de la varianza (VIF) para identificar y posiblemente eliminar variables independientes que estén altamente correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], dtype=int)\n",
    "\n",
    "display(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el warning \"RuntimeWarning: divide by zero encountered in scalar divide\" sugiere que en el cálculo de algún VIF, se está intentando dividir por cero. Esto suele suceder cuando una de las variables independientes en el modelo de regresión es una combinación lineal perfecta de otras variables independientes, o tiene una varianza extremadamente baja que está causando problemas numéricos.\n",
    "\n",
    "Los valores de VIF se muestran en la salida, y muchos de ellos son inf, que significa infinito. Un valor de VIF infinito indica una multicolinealidad perfecta, lo que significa que algunas variables predictoras pueden ser exactamente predichas a partir de otras variables predictoras en el modelo sin error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es bastante evidente cuál podría ser el primer remedio para este problema... Reducir el número de variables, esto se conseguirá estudiando que variables no tienen relevancia para eliminarlas y agrupando las que sí sean positivas para el modelo.\n",
    "\n",
    "Hagamos una primera prueba muy sencilla solo añadiendo drop_first=True a la hora de crear los dummies para eliminar la primera columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns + ['Age'] + gender_columns])\n",
    "\n",
    "mco1 = sm.OLS(y, X).fit()\n",
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplemente con ese paso previo hemos pasado de un Número de Condición = (4.75e+16) que tenía nuestro modelo original a un Número de Condición = (2.94e+03)\n",
    "\n",
    "Y volvemos a ejecutar la técnica VIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver ya prácticamente todas las variables están cerca del valor 1 que como hemos visto indica un problema bien condicionado (bajo riesgo de multicolinealidad).\n",
    "\n",
    "Pero podemos seguir depurándolo. Si nos fijamos hay 2 variables en concreto que resaltan más que las demás, la primera con valor aproximado de 148.191 y la antepenúltima con valor aproximado de 11.852499\n",
    "\n",
    "Viendo esto y además con un poco de sentido común podemos razonar que a la hora de estimar salarios tanto la edad como el género de la persona no debería de ser un factor influyente en el resultado así que eliminemos esas 2 variables y veamos que pasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "\n",
    "#datos.drop('Job Title_Data Analyst', axis=1, inplace=True)\n",
    "#datos.drop('Job Title_Marketing Manager', axis=1, inplace=True)\n",
    "#datos.drop('Job Title_Web Developer', axis=1, inplace=True)\n",
    "\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "gender_columns = [col for col in datos if col.startswith('Gender_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "#X = sm.add_constant(datos[education_columns + job_columns])\n",
    "#X = sm.add_constant(datos[education_columns + ['Years of Experience']])\n",
    "\n",
    "mco1 = sm.OLS(y, X).fit()\n",
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.condition_number)  #Número de Condición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, al eliminar variables que no tienen una relación directa con el salario el Número de Condición = (2.94e+03) que tenía nuestro modelo con Edad y Género se ha reducido a tan solo un Número de Condición = 834 sin sacrificar la medida de bondad R^2^\n",
    "\n",
    "Ya no nos advierte de que pueda haber problemas de multicolinealidad, pero probemos a reducir el número de variables agrupando elementos de la variable Job Title por sectores, esto puede llevar a estimaciones más imprecisas al tener datos más generales de cada ámbito pero probemos a ver que Número de Condición resultaría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:<br><br></strong> Se puede probar quitando los '#' que he puesto en la celda de arriba\n",
    "    <br><br>\n",
    "    Eliminando la variable 'Years of Experience' el Nº de Cond. pasa de 833.5492 a 89.2, pero $R^2$ se ve afectado en un decremento de 0.838 a 0.680\n",
    "    <br><br>\n",
    "    Eliminando la variable 'job_columns' el Nº de Cond. pasa de 833.5492 a 43.8, pero $R^2$ se ve afectado en un decremento de 0.838 a 0.709\n",
    "    <br><br>\n",
    "    Los comandos datos.drop no son necesarios pero están porque pueden reducir el valor de los índices VIF. Simplemente eliminan más columnas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para esta siguiente prueba he creado un duplicado de la base de datos, pero he reducido significativamente el número de variables, especialmente de la columna Job Titles en el que he agrupado distintas categorías en una**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data - Copy.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "\n",
    "y = datos['Salary']\n",
    "\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifs = [oi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como vemos esta reducción/agrupación de los datos nos ha vuelto a reducir el N.º de Condición de 834 a 213**\n",
    "\n",
    "**Además, todo esto ha sido posible sin sacrificar la bondad del ajuste que sigue siendo bastante buena, dando así por solucionado el problema de la multicolinealidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anteriormente, hemos tratado la multicolinealidad, ahora vamos a comprobar si nuestro modelo sigue una distribución normal de los residuos (homocedasticidad) o no (heterocedasticidad).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera Est', 'Jarque-Vera p-val', 'Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(mco1.resid)\n",
    "for i in range(4):\n",
    "    print(name[i], test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El estadístico de Jarque-Bera es 187.68, lo cual es muy alto. Este test combina la asimetría y la curtosis para evaluar si la distribución de los residuos se desvía de la normalidad. Un valor más alto indica una mayor desviación de la normalidad.\n",
    "\n",
    "- El valor p asociado con el estadístico de Jarque-Bera es extremadamente pequeño (alrededor de 1.76e-41). Un valor p tan bajo indica que podemos rechazar la hipótesis nula de que los residuos tienen una distribución normal.\n",
    "\n",
    "- La asimetría de los residuos es -0.1125, lo que indica una leve asimetría hacia la izquierda. Sin embargo, este valor está bastante cerca de cero, lo que sugiere que la asimetría no es muy pronunciada.\n",
    "\n",
    "- La curtosis es 3.7960, que es ligeramente mayor que el valor de 3 que se esperaría de una distribución normal. Esto indica que la distribución de los residuos tiene colas ligeramente más pesadas que una distribución normal, aunque este valor no es muy lejano de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "pyplot.hist(mco1.resid)\n",
    "pyplot.show()\n",
    "qqplot(mco1.resid, line='s')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diag.kstest_normal(mco1.resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El primer valor (0.0676) es el estadístico D de Kolmogorov-Smirnov, que mide la distancia máxima entre la función de distribución acumulativa (CDF) de los residuos y la CDF de una distribución normal. Un valor más alto indica una mayor desviación de la normalidad.\n",
    "\n",
    "- El segundo valor (aproximadamente 0.0) es el valor p del test. Como es menor que cualquier umbral comúnmente usado para significancia estadística (como 0.05 o 0.01), se rechaza la hipótesis nula de que la distribución de los residuos es normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title', 'Gender'], drop_first=True, dtype=int)\n",
    "\n",
    "y = datos['Salary']\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*' y 'Years of Experience'\n",
    "# Filtrar las columnas que comienzan con 'Education Level_'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[education_columns + ['Years of Experience'] + job_columns])\n",
    "\n",
    "from random import choices\n",
    "\n",
    "beta = []\n",
    "n = len(y)\n",
    "for it in range(100):  #repetimos 100 veces la estimacion\n",
    "    I = choices(list(range(n)), k=n)  # elegimos una muestra con repeticion de los datos\n",
    "    mco3 = sm.OLS(y[I], sm.add_constant(X.values[I, :])).fit()  #ajustamos el modelo\n",
    "    beta.append(list(mco3.params))  # guardamos los coeficientes\n",
    "beta = np.array(beta)\n",
    "k = len(X.T)\n",
    "for i in range(k):\n",
    "    q025 = np.percentile(beta[:, i], 2.5)  #percentil 2.5%\n",
    "    q975 = np.percentile(beta[:, i], 97.5)  #percentil 97.5%\n",
    "    media = np.mean(beta[:, i])  #media de los betas\n",
    "    sd = np.std(beta[:, i])  #desviación tipica de los betas\n",
    "    print(i, media, [q025, q975])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializa una lista vacía beta para almacenar los resultados de los coeficientes de las simulaciones de bootstrapping.\n",
    "Realiza 1000 iteraciones de bootstrapping. En cada iteración:\n",
    "- Selecciona una muestra aleatoria con reemplazo de los índices de los datos (esto simula el remuestreo de los datos).\n",
    "- Ajusta un modelo de regresión lineal a la muestra remuestreada.\n",
    "- Guarda los coeficientes estimados del modelo en la lista beta.\n",
    "\n",
    "Los percentiles calculados representan los límites del intervalo de confianza del 95% para los coeficientes, basado en la distribución de bootstrapping.\n",
    "La finalidad de este proceso es estimar la distribución de los coeficientes del modelo de regresión más allá de lo que el modelo ajustado a los datos originales puede proporcionar. El bootstrapping es especialmente útil cuando la distribución de los estimadores no es conocida o es difícil de derivar analíticamente. Los intervalos de confianza calculados a partir de la distribución de bootstrapping pueden proporcionar una medida robusta de la incertidumbre en las estimaciones de los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Years of Experience\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.910836799262646 es el estadístico de prueba de Goldfeld-Quandt.\n",
    "- 0.9855773263736483 es el valor p de la prueba.\n",
    "Dado que el valor p es alto, no hay evidencia suficiente para rechazar la hipótesis nula de homocedasticidad, lo que significa que no hay evidencia de heterocedasticidad en los datos según esta prueba, por tanto, seguiremos probando con otras variables y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Data Scientist\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Software Engineer\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Job Title_Product Manager\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt: \", GQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOLDFELD-QUANDT (Muestras Pequeñas)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_PhD\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt PhD: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_Master\\'s Degree\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt Master: \", GQ)\n",
    "GQ = sms.het_goldfeldquandt(y, sm.add_constant(datos[\"Education Level_High School\"]), split=1 / 3, drop=1 / 3)\n",
    "print(\"Goldfeld Quandt HS: \", GQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con algunas pruebas más observamos como el valor de p de 'Education Level_High School' es minúsculo. Un valor p por debajo de un nivel de significancia común (como 0.05 o 0.01) indica que hay suficiente evidencia para rechazar la hipótesis nula de que la varianza de los residuos es constante a lo largo del rango de los datos, es decir, que hay heterocedasticidad. Sin embargo, para confirmar la hipótesis ratifiquémosla con otras técnicas de detección de heterocedasticidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREUSH-PAGAN\n",
    "BP = sms.het_breuschpagan(mco1.resid, mco1.model.exog)\n",
    "print(\"Breush Pagan: \", BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHITE\n",
    "W = sms.het_white(mco1.resid, mco1.model.exog)\n",
    "print(\"White: \", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En ambos casos, los valores p reportados son 0.0, lo que indica que hay evidencia estadística significativa para rechazar la hipótesis nula de que los errores son homocedásticos (tienen varianzas constantes). Esto significa que los resultados de ambas pruebas apuntan a la presencia de heterocedasticidad en los residuos del modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLEJSER\n",
    "for h in [-2, -1, -0.5, 0.5, 1, 2]:\n",
    "    # Asegúrate de que no haya ceros en los datos antes de elevar a una potencia negativa\n",
    "    X_nonzero = X.replace(0, np.nan)  # Reemplaza 0 por NaN para evitar divisiones por cero\n",
    "    X_transformed = X_nonzero.astype(float) ** h  # Eleva a la potencia de h\n",
    "    X_transformed = X_transformed.fillna(0)  # Reemplaza NaNs con 0s si es necesario, dependiendo del contexto\n",
    "    X_transformed = X_transformed.replace([np.inf, -np.inf], np.nan)  # Reemplaza inf por NaN\n",
    "    X_transformed = X_transformed.dropna(axis=1, how='all')  # Elimina las columnas donde todos los valores son NaN\n",
    "\n",
    "    mcoaux = sm.OLS(abs(mco1.resid), sm.add_constant(X_transformed)).fit()\n",
    "    beta3 = mcoaux.params\n",
    "    pval = beta3.iloc[1]\n",
    "    print(\"h: \", h, \"-> pval:\", pval, \"R2: \", mcoaux.rsquared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Nota:</strong> El test de Glejser es un método utilizado para detectar heterocedasticidad en los errores de un modelo de regresión. Específicamente busca relaciones entre los valores absolutos de los residuos de un modelo de regresión y las variables independientes o transformaciones de estas variables. Si existe una relación significativa, sugiere que la varianza de los errores cambia con el nivel de la variable independiente, lo cual es una forma de heterocedasticidad.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para h= −2, el valor p es muy pequeño, lo que sugiere que hay una relación significativa entre los residuos y las variables independientes elevadas a la potencia de -2, indicando heterocedasticidad.\n",
    "Este patrón se repite para otros valores de h, con valores p muy pequeños, lo que indica que la heterocedasticidad es detectada consistentemente para varias transformaciones de las variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = sm.WLS(y, sm.add_constant(X), weights=1 / y).fit()\n",
    "print(mcp.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viendo que con mco1 no estamos obteniendo las mejores en heterocedasticidad que queremos ni aplicando otros modelos de regresión como la de por mínimos cuadrados ponderados (WLS) probemos con una variante de la regresión por minimos cuadrados ordinarios que llamaremos mco2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refresquemos la memoria sobre mco2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('Salary_Data - Copy.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "y = datos['Salary']\n",
    "\n",
    "# Definir 'X' incluyendo todas las columnas de 'Education Level_*' y 'Years of Experience'\n",
    "# Filtrar las columnas que comienzan con 'Education Level_'\n",
    "education_columns = [col for col in datos if col.startswith('Education Level_')]\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[['Years of Experience'] + job_columns + education_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BREUSH-PAGAN\n",
    "BP = sms.het_breuschpagan(mco2.resid, mco2.model.exog)\n",
    "print(\"Breush Pagan: \", BP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHITE\n",
    "W = sms.het_white(mco2.resid, mco2.model.exog)\n",
    "print(\"White: \", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(mco2.resid)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aunque hay una mejora en mco2 respecto a mco1 vemos que las pruebas siguen indicando presencia de heterocedasticidad, aparte vemos en el factor Durbin-Watson que tenemos problemas de autocorrelación al estar este alejado de 2**\n",
    "\n",
    "**En resumen: aún tenemos problemas de heterocedasticidad y autocorrelación. Estos serán solucionados a continuación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depuración de los datos para MCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "datos = pd.read_csv('Salary_Data - Copy2.csv')\n",
    "datos = pd.get_dummies(datos, columns=['Education Level', 'Job Title'], drop_first=True, dtype=int)\n",
    "\n",
    "#y, lambda_opt = boxcox((datos['Salary']))\n",
    "y = np.sqrt(datos['Salary'])\n",
    "#y = np.log(datos['Salary'])\n",
    "\n",
    "job_columns = [col for col in datos if col.startswith('Job Title_')]\n",
    "\n",
    "X = sm.add_constant(datos[['Years of Experience'] + job_columns])\n",
    "\n",
    "mco2 = sm.OLS(y, X).fit()\n",
    "print(mco2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analizando nuevamente el resumen del modelo podemos apreciar como por fin hemos conseguido reducir el valor Jarque-Bera a valores bajos, esto se ha conseguido eliminando más variables que no aportaban al modelo como 'Education Level' y empleando transformaciones a la variable dependiente. A base de probar, hemos averiguado que la transformación óptima en nuestro caso es por raíz cuadrada, dejamos comentada para probar la transformación por logaritmos y boxcos. También cabe destacar que creamos una nueva copia de los datos llamada 'Salary_Data - Copy2.csv' en el que depuramos aún más los datos, agrupando cada puesto a su departamento.**\n",
    "\n",
    "- Skew: Un valor de 0.010 indica que la distribución de los residuos es muy simétrica.\n",
    "- Kurtosis: Un valor de 3.094 es muy cercano a 3, que es la kurtosis de una distribución normal, indicando una forma de distribución de los residuos razonablemente normal.\n",
    "- Jarque-Bera (JB): Un valor bajo de 2.045 y un valor p de 0.360 sugieren que no hay evidencia suficiente para rechazar la hipótesis de normalidad de los residuos, con lo que ya hemos resuelto el problema de heterocedasticidad.\n",
    "\n",
    "**En resumen, los residuos del modelo parecen estar distribuidos de manera relativamente normal basándose en la prueba Jarque-Bera, dando por concluido así nuestra optimización del modelo en términos de heterocedasticidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(X.T)\n",
    "smg.plot_corr(corr_matrix, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(mco2.resid)\n",
    "print(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como el valor de Durbin-Watson ha pasado a ser aproximadamente 2.0237643721784795 respecto a su versión anterior que era aproximadamente 0.20593535621886824 y como ya sabemos un valor cercano a 2 sugiere que NO hay autocorrelación.\n",
    "\n",
    "Este problema ha sido solucionado simplemente randomizando los datos de la base de datos, ya que al estar manipulándolos previamente los habíamos ordenado y estaban serializados en torno a una de sus variables. Para mantener todo el proceso anterior y ver la evolución del modelo hemos creado una base de datos aparte que es la que se utiliza arriba y la que hemos llamado 'Salary_Data - Copy2.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# New DataFrame for the input data\n",
    "input_data = pd.DataFrame({\n",
    "    'const': 1,\n",
    "    'Years of Experience': [10],  # The number of years of experience\n",
    "    'Job Title_Analyst': [0],     # and then a series of flags for job title, all set to 0...\n",
    "    'Job Title_Developer': [0],   # ...except for the one corresponding to the job title of interest.\n",
    "    'Job Title_Engineer': [1],\n",
    "    'Job Title_Financial': [0],\n",
    "    'Job Title_HR': [0],\n",
    "    'Job Title_Product': [0],\n",
    "    'Job Title_Sales': [0],\n",
    "    'Job Title_Scientist': [0]\n",
    "})\n",
    "\n",
    "# Predict the salary using the fitted model\n",
    "sqrt_predicted_salary = mco2.predict(input_data)\n",
    "# Revert the square root transformation by squaring the predicted salary\n",
    "predicted_salary = np.power(sqrt_predicted_salary, 2)\n",
    "\n",
    "print(f\"The predicted salary is: {predicted_salary:}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones Finales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Significancia de los Predictores:**\n",
    "- Los años de experiencia y los puestos de trabajo específicos han demostrado ser predictores significativos de los salarios, lo que indica que ambos factores son importantes al determinar la compensación de un empleado.\n",
    "- Los coeficientes de regresión para los distintos puestos de trabajo reflejan las diferencias salariales entre las profesiones, ajustadas por la experiencia laboral.\n",
    "\n",
    "2. **Ajuste del Modelo:**\n",
    "- El modelo muestra un buen ajuste general, con un R-cuadrado ajustado que indica que una proporción sustancial de la variabilidad en los salarios se puede explicar con las variables incluidas en el modelo.\n",
    "- Los diagnósticos de residuos sugieren que la asunción de normalidad se mantiene razonablemente bien y aunque hubo indicaciones de autocorrelación y heterocedasticidad, estas pudieron corregirse.\n",
    "\n",
    "3. Diagnóstico de Multicolinealidad:\n",
    "- Se descubrió una multicolinealidad altísima debida al gran número de variables iniciales en los datos (+200).\n",
    "- Se realizaron 2 depuraciones sobre los datos que redujeron drásticamente el N.º de condición y redujo enormemente la multicolinealidad.\n",
    "\n",
    "4. **Diagnóstico de Heterocedasticidad:**\n",
    "- Se detectó heterocedasticidad en los residuos, lo que llevó a aplicar transformaciones y el uso de errores estándar robustos para corregir las inferencias estadísticas.\n",
    "- Se aplicaron transformaciones como la raíz cuadrada, logarítmicas y de Box-Cox para estabilizar la varianza de los residuos y corregir la heterocedasticidad, concluyendo como más óptima la raíz cuadrada.\n",
    "\n",
    "6. **Diagnóstico de Autocorrelación:**\n",
    "- Se encontraron signos de autocorrelación en los residuos, que resulto ser un error en los datos que estaban serializados en torno a una de sus variables consecuencia de la depuración de estos.\n",
    "- Para solucionarlo solo se tuvo que randomizar los datos de nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIN**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
